{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lRVEbkuyn9Zp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 21:53:57.914510: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-10 21:53:58.029101: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-10 21:53:58.031332: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 21:53:59.432123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# імпортуємо необхідні бібліотеки\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# завантажуємо датасет fashion-mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ],
   "metadata": {
    "id": "mA9I6ShGpI1k"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = np.stack((x_train,) * 3, axis=-1)\n",
    "x_test = np.stack((x_test,) * 3, axis=-1)\n",
    "x_train.shape, x_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojuCpy890Mk9",
    "outputId": "488f9981-6dae-4b7d-c0c7-1ed492132e96"
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((60000, 28, 28, 3), (10000, 28, 28, 3))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x_train = np.array([np.array(Image.fromarray(img).resize((75,75), resample=Image.BILINEAR)) for img in x_train])\n",
    "x_test = np.array([np.array(Image.fromarray(img).resize((75,75), resample=Image.BILINEAR)) for img in x_test])\n",
    "\n",
    "x_train.shape, x_test.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JR4ZerD0nfC",
    "outputId": "8d7e482f-b602-413b-9dff-14fa6d94279e"
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((60000, 75, 75, 3), (10000, 75, 75, 3))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# завантажуємо попередньо натреновану модель Inception-v3\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(75, 75, 3))\n",
    "\n",
    "x = keras.layers.Flatten()(base_model.output)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "TXTtK7AnpavC"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "y = model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "     "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TnXtRDxLzjYL",
    "outputId": "8ba0085c-0212-47cf-cf6d-08a1ec6475c5"
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 21:54:22.258558: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1012500000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 394s 205ms/step - loss: 8.8902 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 381s 203ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 369s 197ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Test loss: 2.3026673793792725\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "img_a_in = tf.keras.layers.Input(shape = x_train.shape[1:], name = 'ImageA_Input')\n",
    "img_b_in = tf.keras.layers.Input(shape = x_train.shape[1:], name = 'ImageB_Input')\n",
    "\n",
    "img_a_feat = model(img_a_in)\n",
    "img_b_feat = model(img_b_in)\n",
    "\n",
    "features = concatenate([img_a_feat, img_b_feat], name = 'merge_features')\n",
    "features = tf.keras.layers.Dense(16, activation='linear')(features)\n",
    "features = tf.keras.layers.BatchNormalization()(features)\n",
    "features = tf.keras.layers.Activation('relu')(features)\n",
    "features = tf.keras.layers.Dense(4, activation='linear')(features)\n",
    "features = tf.keras.layers.BatchNormalization()(features)\n",
    "features = tf.keras.layers.Activation('relu')(features)\n",
    "features = tf.keras.layers.Dense(1, activation='sigmoid')(features)\n",
    "\n",
    "siamese_model = tf.keras.models.Model(inputs = [img_a_feat, img_b_feat], outputs = [features], name = 'Siamese_model')\n",
    "siamese_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['mae'])\n",
    "siamese_model.summary()"
   ],
   "metadata": {
    "id": "ujJnLr2U5_nf",
    "outputId": "bf10b53b-acd1-4afa-fff7-fd8e617eab5b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Siamese_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " merge_features (Concatenate)   (None, 20)           0           ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           336         ['merge_features[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 16)          64          ['dense_2[1][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 16)           0           ['batch_normalization_203[1][0]']\n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            68          ['activation_203[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 4)           16          ['dense_3[1][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 4)            0           ['batch_normalization_204[1][0]']\n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            5           ['activation_204[1][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 489\n",
      "Trainable params: 449\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_groups = [x_train[np.where(y_train==i)[0]] for i in np.unique(y_train)]\n",
    "test_groups = [x_test[np.where(y_test==i)[0]] for i in np.unique(y_train)]"
   ],
   "metadata": {
    "id": "9w_kC-jr6DjC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('train groups:', [x.shape[0] for x in train_groups])\n",
    "print('test groups:', [x.shape[0] for x in test_groups])"
   ],
   "metadata": {
    "id": "RIK7svtQ7qJ3",
    "outputId": "71bdc647-95f9-47d4-d7ed-531c98a8bdb1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def gen_random_batch(in_groups, batch_halfsize = 8):\n",
    "    out_img_a, out_img_b, out_score = [], [], []\n",
    "    all_groups = list(range(len(in_groups)))\n",
    "    for match_group in [True, False]:\n",
    "        group_idx = np.random.choice(all_groups, size = batch_halfsize)\n",
    "        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]\n",
    "        if match_group:\n",
    "            b_group_idx = group_idx\n",
    "            out_score += [1] * batch_halfsize\n",
    "        else:\n",
    "            # anything but the same group\n",
    "            non_group_idx = [np.random.choice([i for i in all_groups if i != c_idx]) for c_idx in group_idx]\n",
    "            b_group_idx = non_group_idx\n",
    "            out_score += [0]*batch_halfsize\n",
    "\n",
    "        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]\n",
    "    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)"
   ],
   "metadata": {
    "id": "mUq2OLCR7vo3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_model_output(nb_examples = 3):\n",
    "    pv_a, pv_b, pv_sim = gen_random_batch(test_groups, nb_examples)\n",
    "    pred_sim = siamese_model.predict([model.predict(pv_a), model.predict(pv_b)])\n",
    "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
    "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
    "        ax1.imshow(c_a[:,:,0])\n",
    "        ax1.set_title(f'Image A\\n Actual: { 100 * c_d }')\n",
    "        ax1.axis('off')\n",
    "        ax2.imshow(c_b[:,:,0])\n",
    "        ax2.set_title(f'Image B\\n Predicted: {int( 100 * p_d[0] )}')\n",
    "        ax2.axis('off')\n",
    "    return fig\n",
    "# a completely untrained model\n",
    "_ = show_model_output()"
   ],
   "metadata": {
    "id": "KaKrc_E77yqN",
    "outputId": "2220f127-1b12-4030-8c8e-3cce3d12f6e7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def siam_gen(in_groups, batch_size = 32):\n",
    "    while True:\n",
    "        pv_a, pv_b, pv_sim = gen_random_batch(in_groups, batch_size//2)\n",
    "        yield [model.predict(pv_a), model.predict(pv_b)], pv_sim\n",
    "\n",
    "valid_a, valid_b, valid_sim = gen_random_batch(test_groups, 1024)\n",
    "loss_history = siamese_model.fit(siam_gen(train_groups),\n",
    "    steps_per_epoch = 500,\n",
    "    validation_data=([model.predict(valid_a), model.predict(valid_b)],\n",
    "    valid_sim),\n",
    "    epochs = 4,\n",
    "    verbose = True)"
   ],
   "metadata": {
    "id": "iabjTlUs79GS",
    "outputId": "37d7b63d-6f04-4d5b-ce7b-c9680d8461db",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_ = show_model_output()"
   ],
   "metadata": {
    "id": "fNs9qNK68D5-",
    "outputId": "3ffb44e5-8bf3-4af2-9b4d-168298106fef",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "x_test_features = model.predict(x_test, verbose = True, batch_size=128)\n",
    "\n",
    "tsne_obj = TSNE(n_components=2,\n",
    "    init='pca',\n",
    "    random_state=101,\n",
    "    method='barnes_hut',\n",
    "    n_iter=500,\n",
    "    verbose=1)\n",
    "tsne_features = tsne_obj.fit_transform(x_test_features)"
   ],
   "metadata": {
    "id": "ivAenQxn8Gw1",
    "outputId": "8905c806-1b1a-4191-8eb2-bfc2ccdfe5cb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "obj_categories = [  \n",
    "                    'T-shirt/top','Trouser','Pullover','Dress',\n",
    "                    'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'\n",
    "                 ]\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
    "    plt.scatter(tsne_features[np.where(y_test == c_group), 0],\n",
    "        tsne_features[np.where(y_test == c_group), 1],\n",
    "        marker='o',\n",
    "        color=c_color,\n",
    "        linewidth=1,\n",
    "        alpha=0.8,\n",
    "        label=c_label)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.title('t-SNE on Testing Samples')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('clothes-dist.png')\n",
    "plt.show(block=False)"
   ],
   "metadata": {
    "id": "hG8n1XBv8IsC",
    "outputId": "88d15c73-d368-41a9-a216-9eb1027bffb8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
