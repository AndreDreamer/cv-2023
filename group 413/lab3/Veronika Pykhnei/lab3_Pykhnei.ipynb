{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r3ceUuRt6U0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D \n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout, concatenate\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "lX-pXWGNt8aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /=  255.0\n",
        "x_test /=  255.0"
      ],
      "metadata": {
        "id": "tdd9r8MjuBuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.alexnet(pretrained=True)"
      ],
      "metadata": {
        "id": "yx1dXPhDuFAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (11, 11), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(192, (5, 5),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(384, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "SIV_KQ-muIou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, epochs=10)"
      ],
      "metadata": {
        "id": "N5439HwvuKIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "PmbgV3mVuLyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "R1T-r4KOuMu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)"
      ],
      "metadata": {
        "id": "07T6y8rluPcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows = 3\n",
        "n_cols = 5\n",
        "n_images = n_rows*n_cols\n",
        "plt.figure(figsize=(2*2*n_cols, 2*n_rows))\n",
        "for i in range(n_images):\n",
        "  plt.subplot(n_rows, n_cols, i+1)\n",
        "  plot_image(i, predictions, y_test, x_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cW3LVNoDuRCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('drive/MyDrive/Users/Pykhnei/Datasets/fashion-mnist_train.csv')\n",
        "X_full = data_train.iloc[:,1:]\n",
        "y_full = data_train.iloc[:,:1]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_full, y_full, test_size = 0.3)"
      ],
      "metadata": {
        "id": "xyCnNMmEuRpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "x_test = x_test.values.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "y_train = y_train.values.astype('int')\n",
        "y_test = y_test.values.astype('int')"
      ],
      "metadata": {
        "id": "WukOqem1umgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_groups = [x_train[np.where(y_train==i)[0]] for i in np.unique(y_train)]\n",
        "test_groups = [x_test[np.where(y_test==i)[0]] for i in np.unique(y_train)]"
      ],
      "metadata": {
        "id": "K03Sv5aGuoEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_random_batch(in_groups, batch_halfsize = 8):\n",
        "    out_img_a, out_img_b, out_score = [], [], []\n",
        "    all_groups = list(range(len(in_groups)))\n",
        "    for match_group in [True, False]:\n",
        "        group_idx = np.random.choice(all_groups, size = batch_halfsize)\n",
        "        out_img_a += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in group_idx]\n",
        "        if match_group:\n",
        "            b_group_idx = group_idx\n",
        "            out_score += [1]*batch_halfsize\n",
        "        else:\n",
        "            # anything but the same group\n",
        "            non_group_idx = [np.random.choice([i for i in all_groups if i!=c_idx]) for c_idx in group_idx] \n",
        "            b_group_idx = non_group_idx\n",
        "            out_score += [0]*batch_halfsize\n",
        "            \n",
        "        out_img_b += [in_groups[c_idx][np.random.choice(range(in_groups[c_idx].shape[0]))] for c_idx in b_group_idx]\n",
        "            \n",
        "    return np.stack(out_img_a,0), np.stack(out_img_b,0), np.stack(out_score,0)"
      ],
      "metadata": {
        "id": "z98NbDcDuptj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pv_a, pv_b, pv_sim = gen_random_batch(train_groups, 3)\n",
        "fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
        "for c_a, c_b, c_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, m_axs.T):\n",
        "    ax1.imshow(c_a[:,:,0])\n",
        "    ax1.set_title('Image A')\n",
        "    ax1.axis('off')\n",
        "    ax2.imshow(c_b[:,:,0])\n",
        "    ax2.set_title('Image B\\n Similarity: %3.0f%%' % (100*c_d))\n",
        "    ax2.axis('off')"
      ],
      "metadata": {
        "id": "gjrjlC7QurBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_in = Input(shape = x_train.shape[1:], name = 'FeatureNet_ImageInput')\n",
        "n_layer = img_in\n",
        "for i in range(2):\n",
        "    n_layer = Conv2D(8*2**i, kernel_size = (3,3), activation = 'linear')(n_layer)\n",
        "    n_layer = BatchNormalization()(n_layer)\n",
        "    n_layer = Activation('relu')(n_layer)\n",
        "    n_layer = Conv2D(16*2**i, kernel_size = (3,3), activation = 'linear')(n_layer)\n",
        "    n_layer = BatchNormalization()(n_layer)\n",
        "    n_layer = Activation('relu')(n_layer)\n",
        "    n_layer = MaxPool2D((2,2))(n_layer)\n",
        "n_layer = Flatten()(n_layer)\n",
        "n_layer = Dense(32, activation = 'linear')(n_layer)\n",
        "n_layer = Dropout(0.5)(n_layer)\n",
        "n_layer = BatchNormalization()(n_layer)\n",
        "n_layer = Activation('relu')(n_layer)\n",
        "feature_model = Model(inputs = [img_in], outputs = [n_layer], name = 'FeatureGenerationModel')\n",
        "feature_model.summary()"
      ],
      "metadata": {
        "id": "_wxyF47QushD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_a_in = Input(shape = x_train.shape[1:], name = 'ImageA_Input')\n",
        "img_b_in = Input(shape = x_train.shape[1:], name = 'ImageB_Input')\n",
        "img_a_feat = feature_model(img_a_in)\n",
        "img_b_feat = feature_model(img_b_in)\n",
        "combined_features = concatenate([img_a_feat, img_b_feat], name = 'merge_features')\n",
        "combined_features = Dense(16, activation = 'linear')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(4, activation = 'linear')(combined_features)\n",
        "combined_features = BatchNormalization()(combined_features)\n",
        "combined_features = Activation('relu')(combined_features)\n",
        "combined_features = Dense(1, activation = 'sigmoid')(combined_features)\n",
        "similarity_model = Model(inputs = [img_a_in, img_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
        "similarity_model.summary()"
      ],
      "metadata": {
        "id": "KXhnF5yWu72M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['mae'])"
      ],
      "metadata": {
        "id": "oWf4QA82u8Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_model_output(nb_examples = 3):\n",
        "    pv_a, pv_b, pv_sim = gen_random_batch(test_groups, nb_examples)\n",
        "    pred_sim = similarity_model.predict([pv_a, pv_b])\n",
        "    fig, m_axs = plt.subplots(2, pv_a.shape[0], figsize = (12, 6))\n",
        "    for c_a, c_b, c_d, p_d, (ax1, ax2) in zip(pv_a, pv_b, pv_sim, pred_sim, m_axs.T):\n",
        "        ax1.imshow(c_a[:,:,0])\n",
        "        ax1.set_title('Image A\\n Actual: %3.0f%%' % (100*c_d))\n",
        "        ax1.axis('off')\n",
        "        ax2.imshow(c_b[:,:,0])\n",
        "        ax2.set_title('Image B\\n Predicted: %3.0f%%' % (100*p_d))\n",
        "        ax2.axis('off')\n",
        "    return fig\n",
        "_ = show_model_output()"
      ],
      "metadata": {
        "id": "_Ot9UVytu94-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def siam_gen(in_groups, batch_size = 32):\n",
        "    while True:\n",
        "        pv_a, pv_b, pv_sim = gen_random_batch(train_groups, batch_size//2)\n",
        "        yield [pv_a, pv_b], pv_sim\n",
        "valid_a, valid_b, valid_sim = gen_random_batch(test_groups, 1024)\n",
        "loss_history = similarity_model.fit(siam_gen(train_groups), \n",
        "                               steps_per_epoch = 500,\n",
        "                                               epochs = 10,\n",
        "                                             verbose = True)"
      ],
      "metadata": {
        "id": "EVpj1ilyvAB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = show_model_output()"
      ],
      "metadata": {
        "id": "PZIU-wULvCXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_features = model.predict(x_test, verbose=True, batch_size=128)"
      ],
      "metadata": {
        "id": "V-vcz7gwvGLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne_obj = TSNE(n_components=2,\n",
        "                         init='pca',\n",
        "                         random_state=101,\n",
        "                         method='barnes_hut',\n",
        "                         n_iter=500,\n",
        "                         verbose=2)\n",
        "tsne_features = tsne_obj.fit_transform(x_test_features)"
      ],
      "metadata": {
        "id": "g4biyGBbvGpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_categories = [\n",
        "                    'T-shirt/top','Trouser','Pullover','Dress',\n",
        "                    'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot'\n",
        "                 ]\n",
        "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for c_group, (c_color, c_label) in enumerate(zip(colors, obj_categories)):\n",
        "    plt.scatter(tsne_features[np.where(y_test == c_group), 0],\n",
        "        tsne_features[np.where(y_test == c_group), 1],\n",
        "        marker='o',\n",
        "        color=c_color,\n",
        "        linewidth=1,\n",
        "        alpha=0.8,\n",
        "        label=c_label)\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('t-SNE on Testing Samples')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('image.png')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "QVzz3N2jvPSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}